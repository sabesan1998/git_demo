{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sabesan1998/git_demo/blob/master/Lab_Activity_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#SE4050 - Deep Learning\n",
        "## Lab Activty 04\n",
        "\n",
        "\n",
        "### Student ID : Please Enter your ID Here\n",
        "### Name : Idicate you name with initials"
      ],
      "metadata": {
        "id": "deXIS1MN7jB7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "uiWLjtox7ea4"
      },
      "outputs": [],
      "source": [
        "#Imports\n",
        "#Please include all your imports here\n",
        "import tensorflow as tf \n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, BatchNormalization, Flatten\n",
        "import matplotlib.pyplot as plt "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#rmdir /content/dataset/train/.ipynb_checkpoints\n",
        "rmdir /content/dataset/test/.ipynb_checkpoints"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 133
        },
        "id": "JwGUsihV6xCD",
        "outputId": "bb33aa7e-aacc-474d-9976-1840738cdd15"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-20-13319b5b8ee7>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    rmdir /content/dataset/test/.ipynb_checkpoints\u001b[0m\n\u001b[0m                                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "rmdir /content/dataset/test/.ipynb_checkpoints"
      ],
      "metadata": {
        "id": "F1EVl9RQ7TQB"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Please include any pre-processing or data visualization here. \n",
        "#must include dataset loading, train test split, here. \n",
        "#train = \n",
        "#test = \n",
        "train_path = \"/content/dataset/train/\"\n",
        "test_path = \"/content/dataset/test/\"\n"
      ],
      "metadata": {
        "id": "v_gkOC9w8FQS"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x = plt.imread(\"/content/dataset/train/angry/29.jpg\")\n",
        "x.shape\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1/255.) "
      ],
      "metadata": {
        "id": "bjheomtq9m09",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf807bc-b451-47a6-9a15-32b386cf4bbb"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(220, 221, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train = datagen.flow_from_directory(train_path,target_size=(48,48),class_mode=\"sparse\", seed=1, color_mode=\"grayscale\", batch_size=128)\n",
        "test = datagen.flow_from_directory(test_path,target_size=(48,48),class_mode=\"sparse\", seed=1, color_mode=\"grayscale\", batch_size=128)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jilnSpdSzjvE",
        "outputId": "3140d801-2faa-46a4-b932-c75dbbe86979"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 385 images belonging to 7 classes.\n",
            "Found 70 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train.class_indices)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z0I3Yx9L0UCH",
        "outputId": "8423cb4b-d165-47d8-9749-04e606ec3b2e"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'angry': 0, 'crying': 1, 'embarrassed': 2, 'happy': 3, 'pleased': 4, 'sad': 5, 'shock': 6}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#emotion_dict = {1: \"angry\", 2: \"crying\", 3: \"embarassed\", 4: \"happy\", 5: \"pleased\", 6: \"sad\", 7: \"shock\"}"
      ],
      "metadata": {
        "id": "pCohfrkp0kdY"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x, y = train.next()\n",
        "print(x.shape, y.shape)\n",
        "train.reset()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "senjlvVq6C2U",
        "outputId": "4b78b122-88c8-4c8e-c912-4fc5b138689c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(128, 48, 48, 1) (128,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Please include your model here. use the below fomat. Model variable name should be 'model'\n",
        "# model = keras.Sequential()\n",
        "# model.add(........)\n",
        "model = Sequential([\n",
        "    Conv2D(32, (3,3), input_shape=(48,48,1),padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    Conv2D(32, (3,3), padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.2),\n",
        "    \n",
        "    Conv2D(64,(3,3),padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    Conv2D(64,(3,3), padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.3),\n",
        "    \n",
        "    Conv2D(128,(3,3),padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    Conv2D(128,(3,3), padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    Conv2D(128,(3,3), padding=\"same\"),\n",
        "    LeakyReLU(),\n",
        "    BatchNormalization(),\n",
        "    MaxPooling2D((2,2)),\n",
        "    Dropout(0.4),\n",
        "    \n",
        "    Flatten(),\n",
        "#     tf.keras.layers.GlobalAveragePooling2D(),\n",
        "#     Dropout(0.4),\n",
        "    \n",
        "    Dense(128, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "#     Dense(64, activation=\"relu\"),\n",
        "    \n",
        "    Dense(len(train.class_indices), activation=\"softmax\")\n",
        "])\n",
        "model.summary()\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-3), \n",
        "    loss='sparse_categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jFAUMg_18WVZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f5ea6e22-4291-4aad-84e2-21a8ce78c77c"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_28 (Conv2D)          (None, 48, 48, 32)        320       \n",
            "                                                                 \n",
            " leaky_re_lu_28 (LeakyReLU)  (None, 48, 48, 32)        0         \n",
            "                                                                 \n",
            " conv2d_29 (Conv2D)          (None, 48, 48, 32)        9248      \n",
            "                                                                 \n",
            " leaky_re_lu_29 (LeakyReLU)  (None, 48, 48, 32)        0         \n",
            "                                                                 \n",
            " batch_normalization_12 (Bat  (None, 48, 48, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_12 (MaxPoolin  (None, 24, 24, 32)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_16 (Dropout)        (None, 24, 24, 32)        0         \n",
            "                                                                 \n",
            " conv2d_30 (Conv2D)          (None, 24, 24, 64)        18496     \n",
            "                                                                 \n",
            " leaky_re_lu_30 (LeakyReLU)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " conv2d_31 (Conv2D)          (None, 24, 24, 64)        36928     \n",
            "                                                                 \n",
            " leaky_re_lu_31 (LeakyReLU)  (None, 24, 24, 64)        0         \n",
            "                                                                 \n",
            " batch_normalization_13 (Bat  (None, 24, 24, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_13 (MaxPoolin  (None, 12, 12, 64)       0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_17 (Dropout)        (None, 12, 12, 64)        0         \n",
            "                                                                 \n",
            " conv2d_32 (Conv2D)          (None, 12, 12, 128)       73856     \n",
            "                                                                 \n",
            " leaky_re_lu_32 (LeakyReLU)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_33 (Conv2D)          (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " leaky_re_lu_33 (LeakyReLU)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " conv2d_34 (Conv2D)          (None, 12, 12, 128)       147584    \n",
            "                                                                 \n",
            " leaky_re_lu_34 (LeakyReLU)  (None, 12, 12, 128)       0         \n",
            "                                                                 \n",
            " batch_normalization_14 (Bat  (None, 12, 12, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_14 (MaxPoolin  (None, 6, 6, 128)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_18 (Dropout)        (None, 6, 6, 128)         0         \n",
            "                                                                 \n",
            " flatten_4 (Flatten)         (None, 4608)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 128)               589952    \n",
            "                                                                 \n",
            " dropout_19 (Dropout)        (None, 128)               0         \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 7)                 903       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,025,767\n",
            "Trainable params: 1,025,319\n",
            "Non-trainable params: 448\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Include your model evaluation here\n",
        "#must include accuracy\n",
        "\n",
        "model.fit(train, validation_data=test, epochs=20)"
      ],
      "metadata": {
        "id": "e0bin44H85aa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bb8b567-f981-4044-efa3-f465991fb4ec"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "4/4 [==============================] - 10s 2s/step - loss: 9.5675 - accuracy: 0.1481 - val_loss: 3.6129 - val_accuracy: 0.1429\n",
            "Epoch 2/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 4.8843 - accuracy: 0.1662 - val_loss: 2.0108 - val_accuracy: 0.1429\n",
            "Epoch 3/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 2.8164 - accuracy: 0.1740 - val_loss: 1.9644 - val_accuracy: 0.1286\n",
            "Epoch 4/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 2.2491 - accuracy: 0.2753 - val_loss: 1.9431 - val_accuracy: 0.1429\n",
            "Epoch 5/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 2.0761 - accuracy: 0.1922 - val_loss: 1.9832 - val_accuracy: 0.1429\n",
            "Epoch 6/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 2.0549 - accuracy: 0.1896 - val_loss: 1.9940 - val_accuracy: 0.2000\n",
            "Epoch 7/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 1.9998 - accuracy: 0.1818 - val_loss: 2.0062 - val_accuracy: 0.1286\n",
            "Epoch 8/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.9582 - accuracy: 0.2312 - val_loss: 2.0811 - val_accuracy: 0.1429\n",
            "Epoch 9/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 1.9566 - accuracy: 0.2182 - val_loss: 2.0726 - val_accuracy: 0.1571\n",
            "Epoch 10/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 2.0818 - accuracy: 0.2156 - val_loss: 2.0978 - val_accuracy: 0.1429\n",
            "Epoch 11/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 1.9404 - accuracy: 0.2442 - val_loss: 2.0759 - val_accuracy: 0.1429\n",
            "Epoch 12/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.9298 - accuracy: 0.2026 - val_loss: 2.0659 - val_accuracy: 0.1429\n",
            "Epoch 13/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.8641 - accuracy: 0.2416 - val_loss: 2.0284 - val_accuracy: 0.1714\n",
            "Epoch 14/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.8760 - accuracy: 0.2987 - val_loss: 2.2537 - val_accuracy: 0.1429\n",
            "Epoch 15/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.8786 - accuracy: 0.2753 - val_loss: 2.2942 - val_accuracy: 0.1429\n",
            "Epoch 16/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 2.0719 - accuracy: 0.2753 - val_loss: 2.0024 - val_accuracy: 0.1429\n",
            "Epoch 17/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.9303 - accuracy: 0.2987 - val_loss: 2.2221 - val_accuracy: 0.1571\n",
            "Epoch 18/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 1.9658 - accuracy: 0.2675 - val_loss: 2.2556 - val_accuracy: 0.1571\n",
            "Epoch 19/20\n",
            "4/4 [==============================] - 8s 3s/step - loss: 1.7748 - accuracy: 0.2779 - val_loss: 2.0718 - val_accuracy: 0.1571\n",
            "Epoch 20/20\n",
            "4/4 [==============================] - 8s 2s/step - loss: 1.7005 - accuracy: 0.3143 - val_loss: 2.3203 - val_accuracy: 0.1571\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f31afa9df10>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Include the details of your model here. Marks will be moslty based on the desription below and how it agree with the Model you have built. So it is okay for the accuracy to be low as long as you undertand what the model you have build does and how it behaves. :)\n",
        "\n",
        "Remeber \"More Layers\" doesn't always results in \"High Accuracy\"\n",
        "\n",
        "1.  Layers\n",
        "\n",
        "\n",
        "\n",
        ">  > Layer 1 : Type of Layer, \n",
        "\n",
        "> > > Parameters(trainable)\n",
        "\n",
        "> > > Hyper-Parameters\n",
        "\n",
        "> > > dimmentions\n",
        "\n",
        "> > > usage and reson for parameter selection\n",
        "\n",
        ">  > Layer 2 : Type of layer, \n",
        "\n",
        "> > > Parameters(trainable)\n",
        "\n",
        "> > > Hyper-Parameters\n",
        "\n",
        "> > > dimmentions\n",
        "\n",
        "> > > usage reson for parameter selection\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NjKHIG29-SKh"
      }
    }
  ]
}